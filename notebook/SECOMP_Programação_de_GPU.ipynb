{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tfAkFqXm-uNV"
   },
   "source": [
    "# Ative o uso da GPU em:\n",
    "Runtime > Change runtime type > Hardware Accelerator > GPU > Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MdXY-Ig9DEz6",
    "outputId": "ab868367-2c9a-4bc5-e3bd-06439d3a2bbd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Nov  1 14:25:13 2022       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 520.61.05    Driver Version: 520.61.05    CUDA Version: 11.8     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:01:00.0 Off |                  N/A |\r\n",
      "| N/A   52C    P3    N/A /  N/A |      6MiB /  4096MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A      2756      G   /usr/lib/xorg/Xorg                  4MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UcbDvPhV-alt",
    "outputId": "c207b484-64dd-479a-815d-39f907cc8469"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\r\n",
      "Copyright (c) 2005-2022 NVIDIA Corporation\r\n",
      "Built on Wed_Sep_21_10:33:58_PDT_2022\r\n",
      "Cuda compilation tools, release 11.8, V11.8.89\r\n",
      "Build cuda_11.8.r11.8/compiler.31833905_0\r\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SrSI79uA-9cn",
    "outputId": "414d20a7-ebe5-472e-fec0-98019d8594f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
      "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-yvdtzxv1\n",
      "  Running command git clone -q https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-yvdtzxv1\n",
      "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit aac710a35f52bb78ab34d2e52517237941399eff\n"
     ]
    }
   ],
   "source": [
    "!pip3 install git+https://github.com/andreinechaev/nvcc4jupyter.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HYc3UWA8--wd",
    "outputId": "f8f6f780-ff71-4d2c-c34a-7f74c93296c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "directory /home/m4rquee/projects/secomp22/notebook/src already exists\n",
      "Out bin /home/m4rquee/projects/secomp22/notebook/result.out\n"
     ]
    }
   ],
   "source": [
    "%load_ext nvcc_plugin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rGhSvJ6r_Zjr"
   },
   "source": [
    "# \"Hello World\" em CUDA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QSyGjyJCBeCq",
    "outputId": "4d5823c1-4676-4ced-9c6c-533935bfc735"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World da CPU!\n",
      "Hello World da GPU!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%cu\n",
    "#include <stdio.h>\n",
    "\n",
    "//#   Atributo  Executa no  Chamado por  Nota\n",
    "//# __global__  Device      Host         Precisa ser void\n",
    "//# __device__  Device      Device       Pode retornar qualquer tipo\n",
    "//# __host__    Host        Host         Opcional\n",
    "\n",
    "__global__ void hello() {\n",
    "    printf(\"Hello World da GPU!\\n\");\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    hello<<<1, 1>>>(); // <<<blocos, threads por bloco>>>, executa de forma assíncrona!\n",
    "    printf(\"Hello World da CPU!\\n\");\n",
    "    cudaDeviceSynchronize(); // espera até o kernel finalizar\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qnVUCFm6Benb"
   },
   "source": [
    "# Primeiro exemplo - soma de vetores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nqBcWJhA_E_h",
    "outputId": "81f12b27-3443-44c9-ae6f-4db615b31f17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out[0] = 3.000\n",
      "A soma funcionou!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%cu\n",
    "#include <math.h>\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <assert.h>\n",
    "\n",
    "#define N 100000000\n",
    "#define ERRO_MAX 1e-6\n",
    "\n",
    "__global__ void soma_vetores(float *out, float *a, float *b, int n) {\n",
    "    for (int i = 0; i < n; i++)\n",
    "        out[i] = a[i] + b[i];\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    float *a, *b, *out; // vetores na memória RAM \n",
    "    float *d_a, *d_b, *d_out; // vetores na memória da GPU\n",
    "\n",
    "    // Aloca os vetores no host (memória RAM):\n",
    "    a   = (float*) malloc(sizeof(float) * N);\n",
    "    b   = (float*) malloc(sizeof(float) * N);\n",
    "    out = (float*) malloc(sizeof(float) * N);\n",
    "\n",
    "    // Inicializa os vetores:\n",
    "    for (int i = 0; i < N; i++) {\n",
    "        a[i] = 1.0f;\n",
    "        b[i] = 2.0f;\n",
    "    }\n",
    "\n",
    "    // Aloca os vetores no device (memória da GPU):\n",
    "    cudaMalloc((void**) &d_a, sizeof(float) * N);\n",
    "    cudaMalloc((void**) &d_b, sizeof(float) * N);\n",
    "    cudaMalloc((void**) &d_out, sizeof(float) * N);\n",
    "\n",
    "    //###### TRANSFERÊNCIA DE DADOS ######\n",
    "    // Transfere os dados para a GPU:\n",
    "    cudaMemcpy(d_a, a, sizeof(float) * N, cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(d_b, b, sizeof(float) * N, cudaMemcpyHostToDevice);\n",
    "\n",
    "    //############ COMPUTAÇÃO ############\n",
    "    soma_vetores<<<1, 1>>>(d_out, d_a, d_b, N); // executa a soma\n",
    "    cudaDeviceSynchronize(); // espera até o kernel finalizar\n",
    "    \n",
    "    //###### TRANSFERÊNCIA DE DADOS ######\n",
    "    // Transfere os dados de volta da GPU:\n",
    "    cudaMemcpy(out, d_out, sizeof(float) * N, cudaMemcpyDeviceToHost);\n",
    "\n",
    "    // Testa a resposta:\n",
    "    for (int i = 0; i < N; i++)\n",
    "        assert(fabs(out[i] - a[i] - b[i]) < ERRO_MAX);\n",
    "    printf(\"out[0] = %.3f\\n\", out[0]);\n",
    "    printf(\"A soma funcionou!\\n\");\n",
    "\n",
    "    // Libera os vetores:\n",
    "    cudaFree(d_a);\n",
    "    cudaFree(d_b);\n",
    "    cudaFree(d_out);\n",
    "    free(a); \n",
    "    free(b);\n",
    "    free(out);\n",
    "\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d7HjajtXlVay"
   },
   "source": [
    "# Segundo exemplo - soma de vetores paralela:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9q2IeH8xlWQy",
    "outputId": "6db8088d-6724-4fbb-d8d3-71f336416bf6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out[0] = 3.000\n",
      "A soma funcionou!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%cu\n",
    "#include <math.h>\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <assert.h>\n",
    "\n",
    "#define N 100000000\n",
    "#define ERRO_MAX 1e-6\n",
    "\n",
    "__global__ void soma_vetores(float *out, float *a, float *b, int n) {\n",
    "    int i = blockDim.x * blockIdx.x + threadIdx.x;\n",
    "    if (i < n)\n",
    "        out[i] = a[i] + b[i];\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    float *a, *b, *out; // vetores na memória RAM \n",
    "    float *d_a, *d_b, *d_out; // vetores na memória da GPU\n",
    "\n",
    "    // Aloca os vetores no host (memória RAM):\n",
    "    a   = (float*) malloc(sizeof(float) * N);\n",
    "    b   = (float*) malloc(sizeof(float) * N);\n",
    "    out = (float*) malloc(sizeof(float) * N);\n",
    "\n",
    "    // Inicializa os vetores:\n",
    "    for (int i = 0; i < N; i++) {\n",
    "        a[i] = 1.0f;\n",
    "        b[i] = 2.0f;\n",
    "    }\n",
    "\n",
    "    // Aloca os vetores no device (memória da GPU):\n",
    "    cudaMalloc((void**) &d_a, sizeof(float) * N);\n",
    "    cudaMalloc((void**) &d_b, sizeof(float) * N);\n",
    "    cudaMalloc((void**) &d_out, sizeof(float) * N);\n",
    "\n",
    "    //###### TRANSFERÊNCIA DE DADOS ######\n",
    "    // Transfere os dados para a GPU:\n",
    "    cudaMemcpy(d_a, a, sizeof(float) * N, cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(d_b, b, sizeof(float) * N, cudaMemcpyHostToDevice);\n",
    "\n",
    "    //############ COMPUTAÇÃO ############\n",
    "    int threads = 1024;\n",
    "    int blocos = ((N + threads) / threads);\n",
    "    soma_vetores<<<blocos, threads>>>(d_out, d_a, d_b, N); // executa a soma\n",
    "    cudaDeviceSynchronize(); // espera até o kernel finalizar\n",
    "    \n",
    "    //###### TRANSFERÊNCIA DE DADOS ######\n",
    "    // Transfere os dados de volta da GPU:\n",
    "    cudaMemcpy(out, d_out, sizeof(float) * N, cudaMemcpyDeviceToHost);\n",
    "\n",
    "    // Testa a resposta:\n",
    "    for(int i = 0; i < N; i++)\n",
    "        assert(fabs(out[i] - a[i] - b[i]) < ERRO_MAX);\n",
    "    printf(\"out[0] = %.3f\\n\", out[0]);\n",
    "    printf(\"A soma funcionou!\\n\");\n",
    "\n",
    "    // Libera os vetores:\n",
    "    cudaFree(d_a);\n",
    "    cudaFree(d_b);\n",
    "    cudaFree(d_out);\n",
    "    free(a); \n",
    "    free(b);\n",
    "    free(out);\n",
    "\n",
    "    return 0;\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
